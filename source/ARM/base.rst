================================================================================
ARM 芯片基础知识
================================================================================


名词
================================================================================

非对齐内存访问
++++++++++++++

当你试图从一个不被 N 偶数整除的地址（即 addr % N != 0 ）开始读取 N 字节的数据时，
就 会发生无对齐内存访问。 ARMv6 架构开始满足。

* 一些架构能够透明地执行非对齐内存访问，但通常会有很大的性能代价
* 当不对齐的访问发生时，一些架构会引发处理器异常。异常处理程序能够纠正不对齐的访
  问，但要付出很大的性能代价。
* 一些架构在发生不对齐访问时，会引发处理器异常，但异常中并没有包含足够的信息来纠
  正不对齐访问。
* 有些架构不能进行无对齐内存访问，但会默默地执行与请求不同的内存访问，从而导致难
  以发现的微妙的代码错误!

自然对齐
++++++++

当访问 N 个字节的内存时，基础内存地址必须被 N 平均分割，即 addr % N == 0。

在现实中，只有少数架构在所有大小的内存访问上都要求自然对齐。然而，我们必须考虑所
有支持的架构；编写满足自然对齐要求的代码是实现完全可移植性的最简单方法。


独占访问
++++++++

处理器对某个内存地址的数据，在某个时间段内享有独有的访问。


Thumb interworking
++++++++++++++++++

ARM / Thumb 指令混合编程之代码交织。

编译参数需使用 "-mthumb-interwork"


内存模型
++++++++

实际的内存访问顺序可能与程序的 load/strore 操作顺序不完全一致。
如果让两者的顺序完全一致，就是强序内存模型，也称为顺序一致性模型。

高性能处理器可以支持推测性内存读取（ speculative memory read ）、指令多发射（ 
multiple issuing of instruction ），乱序执行（ out-of-order execution ）等多种技
术。这些技术与其它技术一起，为访存的硬件重新排序提供了进一步的可能性

* 指令多发射：处理器可以在每个时钟周期发出和执行多条指令。一些指令可以并行到达流
  水线的执行阶段，因此这些指令的执行顺序可能会以与程序中的顺序不同。
* 乱序执行：此技术允许处理器可以乱序的执行非相关（依赖）的指令，一些指令可能因为
  某些原因暂时停留在执行阶段，但这些指令不会阻止其它的非相关指令完成。
* 推测：处理器在执行条件指令（例如分支指令）时，可以根据一定的规则进行推测，尽可
  能早的装入指令，也就是尽量填充流水线，这样处理器就不会空闲着。
* load/store 优化：处理器为了减少访存次数，可以把多个访存操作合并成一笔操作。
* 编译器优化：优化编译器可以对指令重新排序，以隐藏延迟或充分利用硬件功能。在单核
  系统中，这种重新排序的影响对程序员来说是透明的，因为单个处理器可以检查并确保指
  令的依赖性，避免竞争现象。但是在多核系统中，处理器核之间共享存储，共享数据，目
  前编译器没有办法知道处理器核之间的依赖关系。


ARM 架构过程调用标准 AAPCS
++++++++++++++++++++++++++

#. 参数和返回值传递，对于简单的情况，输入参数由 R0-R3 分别用来记录第1到第4个参数。
   当传递的参数超过 4 个时，就需要借助栈来保存参数。函数的返回值通常保存在 R0 中，
   若返回值为 64 位的， R1 也用来保存返回值。

#. 函数调用中的寄存器用法。函数或子程序应该保持 R4-R11 、 R13 和 R14 的数值。若
   这些寄存器在函数或子程序执行期间被修改，则其函数应该保持在栈中并在返回调用代
   码前恢复。这几个寄存器也被称作“被调用者保存寄存器”，也就是需要被调用者（例如
   子函数，中断等）进行保存的寄存器。而对于 R0-R3 、 R12 、则属于调用者保存寄存
   器，这几个寄存器是需要调用者做保存工作。在发生异常或中断啊时， R0-R3 、 R12 、
   SP 、 PC 会硬件自动进程压栈。

#. 链接寄存器 LR 用于函数或子程序调用时返回地址的保存，若某函数需要调用另外一个
   函数或子程序，则它需要首先将 LR 的数值保存到栈中，否则，当执行了函数调用后， 
   LR 的当前值就会丢失。

参考官方 AAPCS 文档： 
    `2023Q1 <https://github.com/ARM-software/abi-aa/blob/2023Q1/aapcs32/aapcs32.rst>`_


受保护内存系统体系结构 PMSA
+++++++++++++++++++++++++++

PMSA 基于 MPU 内存保护单元； PMSA 与基于 VMSA 的 MMU 相比提供了更简单的内存保护
方案。简化适用于硬件和软件。PMSAv7 处理器依赖 MPU 类型寄存器来识别。


特权级
++++++

程序有特权级和非特权级之分；特权级程序运行在特权级别上，可以访问系统所有资源，
非特权级程序运行在非特权级别上，它的访问有限制，例如不能访问系统内核寄存器； 
Handler 模式运行在特权级别上， Thread 模式可以运行在特权或者非特权级上。


cache 与 MPU 和 MMU
================================================================================

* cache 是高速缓存，是一个具体的硬件
* MPU 是内存保护单元，也是一个独立的硬件，用来控制内存的属性。
* MMU 是 MPU 的升级版
  


异常
================================================================================

对于异常分组和优先级的设定，可以参考： 
`异常处理 <https://blog.csdn.net/tilblackout/article/details/128182195>`_ ;
其中基于 cortex-M3 描述了异常优先级的设定，以及优先级分组的的原理。









